# UnifiedRouteManager Part 3: Performance & Operations

> ‚ö° **Performance & Production Readiness** - Advanced monitoring, caching, and operational excellence

## üìñ Part 3 Overview

**Goal**: ‡πÄ‡∏û‡∏¥‡πà‡∏° advanced performance monitoring, caching strategies ‡πÅ‡∏•‡∏∞ production operations

**Prerequisites**: ‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥ Part 1 (Foundation) ‡πÅ‡∏•‡∏∞ Part 2 (Security & Development) ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏Å‡πà‡∏≠‡∏ô

**Learning Outcome**: ‡∏°‡∏µ production-grade API ‡∏ó‡∏µ‡πà‡∏û‡∏£‡πâ‡∏≠‡∏° scale, monitor ‡πÅ‡∏•‡∏∞ operate ‡πÉ‡∏ô enterprise environment

**Time Investment**: 1-2 ‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå (1-2 ‡∏ä‡∏°. ‡∏≠‡πà‡∏≤‡∏ô + 4-6 ‡∏ä‡∏°. ‡∏•‡∏á‡∏°‡∏∑‡∏≠‡∏ó‡∏≥)

---

## üéØ Part 3 Contents

1. **üìä Performance Monitoring** - Advanced metrics, alerts, observability
2. **‚ö° Caching System** - Redis, CDN, intelligent caching strategies  
3. **üè• Operations & Health** - Health checks, graceful shutdown, circuit breakers

---

## 1. üìä **Performance Monitoring**

### **Advanced Metrics Collection**

```typescript
// foundations/monitoring/metrics-collector.ts
export interface RouteMetrics {
  readonly routeKey: string;
  readonly method: string;
  readonly path: string;
  readonly version?: string;
  readonly totalRequests: number;
  readonly successfulRequests: number;
  readonly failedRequests: number;
  readonly errorsByCode: Record<number, number>;
  readonly responseTimeMetrics: {
    readonly min: number;
    readonly max: number;
    readonly mean: number;
    readonly median: number;
    readonly p95: number;
    readonly p99: number;
  };
  readonly requestsPerSecond: number;
  readonly lastRequest: Date;
  readonly slowRequests: number; // > threshold
  readonly memoryUsage: number;
  readonly tags: readonly string[];
}

export interface SystemMetrics {
  readonly timestamp: Date;
  readonly cpu: {
    readonly usage: number; // percentage
    readonly loadAverage: readonly number[];
  };
  readonly memory: {
    readonly used: number;
    readonly free: number;
    readonly total: number;
    readonly heapUsed: number;
    readonly heapTotal: number;
  };
  readonly eventLoop: {
    readonly delay: number;
    readonly utilization: number;
  };
  readonly gc: {
    readonly collections: number;
    readonly duration: number;
  };
}

export interface PerformanceAlert {
  readonly id: string;
  readonly type: 'slow_route' | 'high_error_rate' | 'memory_leak' | 'high_cpu' | 'event_loop_lag';
  readonly severity: 'low' | 'medium' | 'high' | 'critical';
  readonly route?: string;
  readonly message: string;
  readonly value: number;
  readonly threshold: number;
  readonly timestamp: Date;
  readonly resolved?: Date;
}

export interface MetricsCollector {
  trackRequest(
    route: RouteDefinition, 
    responseTime: number, 
    statusCode: number,
    memoryDelta?: number
  ): Promise<void>;
  getRouteMetrics(routeKey?: string): Promise<RouteMetrics[]>;
  getSystemMetrics(): Promise<SystemMetrics>;
  getActiveAlerts(): Promise<PerformanceAlert[]>;
  generatePerformanceReport(timeRange?: { from: Date; to: Date }): Promise<PerformanceReport>;
  startMonitoring(): void;
  stopMonitoring(): void;
}

export const createAdvancedMetricsCollector = (config: {
  readonly slowRequestThreshold: number;
  readonly highErrorRateThreshold: number;
  readonly memoryLeakThreshold: number;
  readonly cpuThreshold: number;
  readonly eventLoopThreshold: number;
  readonly alertingEnabled: boolean;
  readonly retentionDays: number;
} = {
  slowRequestThreshold: 1000,
  highErrorRateThreshold: 0.05,
  memoryLeakThreshold: 100 * 1024 * 1024, // 100MB
  cpuThreshold: 80,
  eventLoopThreshold: 100,
  alertingEnabled: true,
  retentionDays: 30
}): MetricsCollector => {
  
  const routeMetrics = new Map<string, {
    metrics: RouteMetrics;
    requestTimings: Array<{ timestamp: Date; responseTime: number; statusCode: number; memory: number }>;
  }>();
  
  const alerts = new Map<string, PerformanceAlert>();
  let monitoringInterval: NodeJS.Timeout | null = null;

  const getRouteKey = (route: RouteDefinition): string => 
    `${route.metadata.method}:${route.metadata.path}:${(route.metadata as any).version || 'default'}`;

  return {
    trackRequest: async (
      route: RouteDefinition, 
      responseTime: number, 
      statusCode: number,
      memoryDelta: number = 0
    ): Promise<void> => {
      const routeKey = getRouteKey(route);
      const timestamp = new Date();

      if (!routeMetrics.has(routeKey)) {
        routeMetrics.set(routeKey, {
          metrics: {
            routeKey,
            method: route.metadata.method,
            path: route.metadata.path,
            version: (route.metadata as any).version,
            totalRequests: 0,
            successfulRequests: 0,
            failedRequests: 0,
            errorsByCode: {},
            responseTimeMetrics: {
              min: Infinity,
              max: 0,
              mean: 0,
              median: 0,
              p95: 0,
              p99: 0
            },
            requestsPerSecond: 0,
            lastRequest: timestamp,
            slowRequests: 0,
            memoryUsage: 0,
            tags: route.metadata.tags || []
          },
          requestTimings: []
        });
      }

      const routeData = routeMetrics.get(routeKey)!;

      // Add new timing data
      routeData.requestTimings.push({ timestamp, responseTime, statusCode, memory: memoryDelta });

      // Clean old data (retention policy)
      const cutoffDate = new Date(Date.now() - config.retentionDays * 24 * 60 * 60 * 1000);
      routeData.requestTimings = routeData.requestTimings.filter(timing => timing.timestamp > cutoffDate);

      // Update metrics
      const timings = routeData.requestTimings;
      const responseTimes = timings.map(t => t.responseTime).sort((a, b) => a - b);
      const successfulRequests = timings.filter(t => t.statusCode < 400).length;
      const failedRequests = timings.length - successfulRequests;
      
      // Error breakdown
      const errorsByCode: Record<number, number> = {};
      timings.forEach(timing => {
        if (timing.statusCode >= 400) {
          errorsByCode[timing.statusCode] = (errorsByCode[timing.statusCode] || 0) + 1;
        }
      });

      // Calculate percentiles
      const p95Index = Math.floor(responseTimes.length * 0.95);
      const p99Index = Math.floor(responseTimes.length * 0.99);
      const medianIndex = Math.floor(responseTimes.length * 0.5);

      // Calculate RPS (requests per second over last minute)
      const oneMinuteAgo = new Date(Date.now() - 60000);
      const recentRequests = timings.filter(t => t.timestamp > oneMinuteAgo);

      routeData.metrics = {
        ...routeData.metrics,
        totalRequests: timings.length,
        successfulRequests,
        failedRequests,
        errorsByCode,
        responseTimeMetrics: {
          min: responseTimes[0] || 0,
          max: responseTimes[responseTimes.length - 1] || 0,
          mean: responseTimes.reduce((sum, time) => sum + time, 0) / responseTimes.length || 0,
          median: responseTimes[medianIndex] || 0,
          p95: responseTimes[p95Index] || 0,
          p99: responseTimes[p99Index] || 0
        },
        requestsPerSecond: recentRequests.length / 60,
        lastRequest: timestamp,
        slowRequests: responseTimes.filter(time => time > config.slowRequestThreshold).length,
        memoryUsage: timings.reduce((sum, t) => sum + t.memory, 0) / timings.length
      };

      // Check for alerts
      if (config.alertingEnabled) {
        await checkForAlerts(routeData.metrics, config, alerts);
      }
    },

    getRouteMetrics: async (routeKey?: string): Promise<RouteMetrics[]> => {
      if (routeKey) {
        const routeData = routeMetrics.get(routeKey);
        return routeData ? [routeData.metrics] : [];
      }

      return Array.from(routeMetrics.values()).map(data => data.metrics);
    },

    getSystemMetrics: async (): Promise<SystemMetrics> => {
      const memUsage = process.memoryUsage();
      const cpuUsage = process.cpuUsage();
      
      return {
        timestamp: new Date(),
        cpu: {
          usage: (cpuUsage.user + cpuUsage.system) / 1000000, // Convert to percentage (rough estimate)
          loadAverage: require('os').loadavg()
        },
        memory: {
          used: memUsage.rss,
          free: require('os').freemem(),
          total: require('os').totalmem(),
          heapUsed: memUsage.heapUsed,
          heapTotal: memUsage.heapTotal
        },
        eventLoop: {
          delay: await measureEventLoopDelay(),
          utilization: await measureEventLoopUtilization()
        },
        gc: {
          collections: getGCStats().collections,
          duration: getGCStats().duration
        }
      };
    },

    getActiveAlerts: async (): Promise<PerformanceAlert[]> => {
      return Array.from(alerts.values()).filter(alert => !alert.resolved);
    },

    generatePerformanceReport: async (timeRange?: { from: Date; to: Date }): Promise<PerformanceReport> => {
      const routes = Array.from(routeMetrics.values()).map(data => data.metrics);
      const systemMetrics = await createAdvancedMetricsCollector(config).getSystemMetrics();
      const activeAlerts = Array.from(alerts.values()).filter(alert => !alert.resolved);

      // Calculate overall stats
      const totalRequests = routes.reduce((sum, route) => sum + route.totalRequests, 0);
      const totalErrors = routes.reduce((sum, route) => sum + route.failedRequests, 0);
      const overallErrorRate = totalRequests > 0 ? totalErrors / totalRequests : 0;
      const averageResponseTime = routes.reduce((sum, route) => 
        sum + (route.responseTimeMetrics.mean * route.totalRequests), 0) / totalRequests || 0;

      // Find problematic routes
      const slowestRoutes = routes
        .filter(route => route.responseTimeMetrics.mean > config.slowRequestThreshold)
        .sort((a, b) => b.responseTimeMetrics.mean - a.responseTimeMetrics.mean)
        .slice(0, 5);

      const errorProneRoutes = routes
        .filter(route => route.totalRequests > 0 && route.failedRequests / route.totalRequests > config.highErrorRateThreshold)
        .sort((a, b) => (b.failedRequests / b.totalRequests) - (a.failedRequests / a.totalRequests))
        .slice(0, 5);

      const mostUsedRoutes = routes
        .sort((a, b) => b.totalRequests - a.totalRequests)
        .slice(0, 10);

      return {
        generatedAt: new Date(),
        timeRange: timeRange || {
          from: new Date(Date.now() - 24 * 60 * 60 * 1000),
          to: new Date()
        },
        summary: {
          totalRequests,
          totalErrors,
          errorRate: overallErrorRate,
          averageResponseTime,
          totalRoutes: routes.length,
          activeAlerts: activeAlerts.length
        },
        systemMetrics,
        routeMetrics: {
          slowestRoutes,
          errorProneRoutes,
          mostUsedRoutes,
          routeCount: routes.length
        },
        alerts: activeAlerts,
        recommendations: generatePerformanceRecommendations(routes, systemMetrics, config)
      };
    },

    startMonitoring: (): void => {
      if (monitoringInterval) return;

      monitoringInterval = setInterval(async () => {
        const systemMetrics = await createAdvancedMetricsCollector(config).getSystemMetrics();
        await checkSystemAlerts(systemMetrics, config, alerts);
      }, 30000); // Check every 30 seconds
    },

    stopMonitoring: (): void => {
      if (monitoringInterval) {
        clearInterval(monitoringInterval);
        monitoringInterval = null;
      }
    }
  };
};

// Helper functions
const checkForAlerts = async (
  metrics: RouteMetrics,
  config: any,
  alerts: Map<string, PerformanceAlert>
): Promise<void> => {
  const alertId = `route-${metrics.routeKey}`;

  // Slow route alert
  if (metrics.responseTimeMetrics.mean > config.slowRequestThreshold) {
    if (!alerts.has(`${alertId}-slow`)) {
      alerts.set(`${alertId}-slow`, {
        id: `${alertId}-slow`,
        type: 'slow_route',
        severity: metrics.responseTimeMetrics.mean > config.slowRequestThreshold * 2 ? 'critical' : 'high',
        route: metrics.routeKey,
        message: `Route ${metrics.routeKey} has average response time of ${metrics.responseTimeMetrics.mean.toFixed(2)}ms`,
        value: metrics.responseTimeMetrics.mean,
        threshold: config.slowRequestThreshold,
        timestamp: new Date()
      });
    }
  }

  // High error rate alert
  const errorRate = metrics.totalRequests > 0 ? metrics.failedRequests / metrics.totalRequests : 0;
  if (errorRate > config.highErrorRateThreshold) {
    if (!alerts.has(`${alertId}-errors`)) {
      alerts.set(`${alertId}-errors`, {
        id: `${alertId}-errors`,
        type: 'high_error_rate',
        severity: errorRate > 0.1 ? 'critical' : 'high',
        route: metrics.routeKey,
        message: `Route ${metrics.routeKey} has error rate of ${(errorRate * 100).toFixed(2)}%`,
        value: errorRate,
        threshold: config.highErrorRateThreshold,
        timestamp: new Date()
      });
    }
  }
};

const checkSystemAlerts = async (
  systemMetrics: SystemMetrics,
  config: any,
  alerts: Map<string, PerformanceAlert>
): Promise<void> => {
  // High CPU alert
  if (systemMetrics.cpu.usage > config.cpuThreshold) {
    const alertId = 'system-cpu';
    if (!alerts.has(alertId)) {
      alerts.set(alertId, {
        id: alertId,
        type: 'high_cpu',
        severity: systemMetrics.cpu.usage > 90 ? 'critical' : 'high',
        message: `High CPU usage: ${systemMetrics.cpu.usage.toFixed(2)}%`,
        value: systemMetrics.cpu.usage,
        threshold: config.cpuThreshold,
        timestamp: new Date()
      });
    }
  }

  // Event loop lag alert
  if (systemMetrics.eventLoop.delay > config.eventLoopThreshold) {
    const alertId = 'system-eventloop';
    if (!alerts.has(alertId)) {
      alerts.set(alertId, {
        id: alertId,
        type: 'event_loop_lag',
        severity: systemMetrics.eventLoop.delay > 200 ? 'critical' : 'high',
        message: `High event loop delay: ${systemMetrics.eventLoop.delay.toFixed(2)}ms`,
        value: systemMetrics.eventLoop.delay,
        threshold: config.eventLoopThreshold,
        timestamp: new Date()
      });
    }
  }

  // Memory usage alert
  const memoryUsagePercent = (systemMetrics.memory.used / systemMetrics.memory.total) * 100;
  if (memoryUsagePercent > 80) {
    const alertId = 'system-memory';
    if (!alerts.has(alertId)) {
      alerts.set(alertId, {
        id: alertId,
        type: 'memory_leak',
        severity: memoryUsagePercent > 90 ? 'critical' : 'high',
        message: `High memory usage: ${memoryUsagePercent.toFixed(2)}%`,
        value: memoryUsagePercent,
        threshold: 80,
        timestamp: new Date()
      });
    }
  }
};

const generatePerformanceRecommendations = (
  routes: RouteMetrics[],
  systemMetrics: SystemMetrics,
  config: any
): readonly string[] => {
  const recommendations: string[] = [];

  // Route-specific recommendations
  const slowRoutes = routes.filter(r => r.responseTimeMetrics.mean > config.slowRequestThreshold);
  if (slowRoutes.length > 0) {
    recommendations.push(`Consider optimizing ${slowRoutes.length} slow routes or adding caching`);
  }

  const errorProneRoutes = routes.filter(r => r.totalRequests > 0 && r.failedRequests / r.totalRequests > config.highErrorRateThreshold);
  if (errorProneRoutes.length > 0) {
    recommendations.push(`Investigate ${errorProneRoutes.length} routes with high error rates`);
  }

  // System recommendations
  if (systemMetrics.cpu.usage > 70) {
    recommendations.push('Consider scaling horizontally - CPU usage is high');
  }

  if (systemMetrics.eventLoop.delay > 50) {
    recommendations.push('Event loop delay detected - review synchronous operations');
  }

  const memoryUsagePercent = (systemMetrics.memory.used / systemMetrics.memory.total) * 100;
  if (memoryUsagePercent > 70) {
    recommendations.push('Memory usage is high - consider garbage collection tuning');
  }

  return recommendations;
};

// Mock implementations for Node.js APIs
const measureEventLoopDelay = async (): Promise<number> => {
  return new Promise(resolve => {
    const start = process.hrtime.bigint();
    setImmediate(() => {
      const delay = Number(process.hrtime.bigint() - start) / 1000000; // Convert to ms
      resolve(delay);
    });
  });
};

const measureEventLoopUtilization = async (): Promise<number> => {
  // This would use perf_hooks.performance.eventLoopUtilization() in real Node.js
  return Math.random() * 100; // Mock value
};

const getGCStats = () => {
  // This would use perf_hooks or v8 module in real Node.js
  return { collections: Math.floor(Math.random() * 100), duration: Math.random() * 50 };
};

export interface PerformanceReport {
  readonly generatedAt: Date;
  readonly timeRange: { from: Date; to: Date };
  readonly summary: {
    readonly totalRequests: number;
    readonly totalErrors: number;
    readonly errorRate: number;
    readonly averageResponseTime: number;
    readonly totalRoutes: number;
    readonly activeAlerts: number;
  };
  readonly systemMetrics: SystemMetrics;
  readonly routeMetrics: {
    readonly slowestRoutes: readonly RouteMetrics[];
    readonly errorProneRoutes: readonly RouteMetrics[];
    readonly mostUsedRoutes: readonly RouteMetrics[];
    readonly routeCount: number;
  };
  readonly alerts: readonly PerformanceAlert[];
  readonly recommendations: readonly string[];
}
```

### **Performance Monitoring Middleware**

```typescript
// foundations/monitoring/performance-middleware.ts
export const createPerformanceTrackingMiddleware = (
  metricsCollector: MetricsCollector,
  route: RouteDefinition
): MiddlewareDefinition => ({
  name: 'performance-tracking',
  priority: 2, // Very early in pipeline
  handler: async (context: UnifiedHttpContext): Promise<boolean> => {
    const startTime = process.hrtime.bigint();
    const startMemory = process.memoryUsage().heapUsed;

    // Add performance tracking to context
    (context as any).performance = {
      startTime,
      startMemory,
      route
    };

    // Override response methods to capture metrics
    const originalJson = context.response.json;
    const originalSend = context.response.send;
    
    let responseTracked = false;
    
    const trackResponse = async (statusCode: number) => {
      if (responseTracked) return;
      responseTracked = true;

      const endTime = process.hrtime.bigint();
      const endMemory = process.memoryUsage().heapUsed;
      
      const responseTime = Number(endTime - startTime) / 1000000; // Convert to ms
      const memoryDelta = endMemory - startMemory;

      await metricsCollector.trackRequest(route, responseTime, statusCode, memoryDelta);
    };

    context.response.json = function<T>(data: T) {
      const statusCode = (this as any).statusCode || 200;
      setImmediate(() => trackResponse(statusCode));
      return originalJson.call(this, data);
    };

    context.response.send = function(data: string) {
      const statusCode = (this as any).statusCode || 200;
      setImmediate(() => trackResponse(statusCode));
      return originalSend.call(this, data);
    };

    return true;
  }
});

// Request correlation middleware for distributed tracing
export const createRequestCorrelationMiddleware = (): MiddlewareDefinition => ({
  name: 'request-correlation',
  priority: 3,
  handler: async (context: UnifiedHttpContext): Promise<boolean> => {
    // Get or generate correlation ID
    const correlationId = context.request.headers['x-correlation-id'] || 
                         context.request.headers['x-request-id'] ||
                         generateCorrelationId();

    // Add to context
    (context as any).correlationId = correlationId;

    // Add to response headers
    context.response.header('X-Correlation-ID', correlationId);

    // Add structured logging context
    const originalConsole = console.log;
    console.log = (...args: any[]) => {
      originalConsole(`[${correlationId}]`, ...args);
    };

    return true;
  }
});

const generateCorrelationId = (): string => {
  return `req_${Date.now()}_${Math.random().toString(36).substring(2, 15)}`;
};
```

---

## 2. ‚ö° **Caching System**

### **Advanced Cache Manager**

```typescript
// foundations/caching/cache-manager.ts
export interface CacheConfig {
  readonly ttl: number; // Time to live in seconds
  readonly key?: string;
  readonly tags?: readonly string[];
  readonly invalidateOn?: readonly string[];
  readonly staleWhileRevalidate?: boolean;
  readonly compress?: boolean;
  readonly serialize?: 'json' | 'msgpack';
}

export interface CacheProvider {
  get<T>(key: string): Promise<T | null>;
  set<T>(key: string, value: T, ttl: number): Promise<void>;
  del(key: string): Promise<void>;
  delByPattern(pattern: string): Promise<number>;
  delByTag(tag: string): Promise<number>;
  exists(key: string): Promise<boolean>;
  ttl(key: string): Promise<number>;
  health(): Promise<{ status: 'healthy' | 'unhealthy'; latency: number }>;
}

// Redis cache provider
export const createRedisCacheProvider = (redis: any): CacheProvider => ({
  get: async <T>(key: string): Promise<T | null> => {
    try {
      const value = await redis.get(key);
      return value ? JSON.parse(value) : null;
    } catch (error) {
      console.error('Cache get error:', error);
      return null;
    }
  },

  set: async <T>(key: string, value: T, ttl: number): Promise<void> => {
    try {
      const serialized = JSON.stringify(value);
      await redis.setex(key, ttl, serialized);
    } catch (error) {
      console.error('Cache set error:', error);
    }
  },

  del: async (key: string): Promise<void> => {
    try {
      await redis.del(key);
    } catch (error) {
      console.error('Cache del error:', error);
    }
  },

  delByPattern: async (pattern: string): Promise<number> => {
    try {
      const keys = await redis.keys(pattern);
      if (keys.length > 0) {
        return await redis.del(...keys);
      }
      return 0;
    } catch (error) {
      console.error('Cache delByPattern error:', error);
      return 0;
    }
  },

  delByTag: async (tag: string): Promise<number> => {
    try {
      const tagKey = `tag:${tag}`;
      const keys = await redis.smembers(tagKey);
      if (keys.length > 0) {
        await redis.del(...keys);
        await redis.del(tagKey);
        return keys.length;
      }
      return 0;
    } catch (error) {
      console.error('Cache delByTag error:', error);
      return 0;
    }
  },

  exists: async (key: string): Promise<boolean> => {
    try {
      const result = await redis.exists(key);
      return result === 1;
    } catch (error) {
      console.error('Cache exists error:', error);
      return false;
    }
  },

  ttl: async (key: string): Promise<number> => {
    try {
      return await redis.ttl(key);
    } catch (error) {
      console.error('Cache ttl error:', error);
      return -1;
    }
  },

  health: async (): Promise<{ status: 'healthy' | 'unhealthy'; latency: number }> => {
    const start = Date.now();
    try {
      await redis.ping();
      return { status: 'healthy', latency: Date.now() - start };
    } catch (error) {
      return { status: 'unhealthy', latency: Date.now() - start };
    }
  }
});

// In-memory cache provider (for development)
export const createInMemoryCacheProvider = (): CacheProvider => {
  const cache = new Map<string, { value: any; expires: number; tags: string[] }>();
  const tags = new Map<string, Set<string>>();

  const cleanup = () => {
    const now = Date.now();
    for (const [key, entry] of cache) {
      if (entry.expires < now) {
        cache.delete(key);
        // Remove from tag indexes
        entry.tags.forEach(tag => {
          tags.get(tag)?.delete(key);
        });
      }
    }
  };

  // Cleanup expired entries every minute
  setInterval(cleanup, 60000);

  return {
    get: async <T>(key: string): Promise<T | null> => {
      const entry = cache.get(key);
      if (!entry || entry.expires < Date.now()) {
        cache.delete(key);
        return null;
      }
      return entry.value;
    },

    set: async <T>(key: string, value: T, ttl: number): Promise<void> => {
      const expires = Date.now() + (ttl * 1000);
      cache.set(key, { value, expires, tags: [] });
    },

    del: async (key: string): Promise<void> => {
      cache.delete(key);
    },

    delByPattern: async (pattern: string): Promise<number> => {
      const regex = new RegExp(pattern.replace(/\*/g, '.*'));
      let deleted = 0;
      for (const key of cache.keys()) {
        if (regex.test(key)) {
          cache.delete(key);
          deleted++;
        }
      }
      return deleted;
    },

    delByTag: async (tag: string): Promise<number> => {
      const taggedKeys = tags.get(tag);
      if (!taggedKeys) return 0;
      
      let deleted = 0;
      for (const key of taggedKeys) {
        if (cache.delete(key)) deleted++;
      }
      tags.delete(tag);
      return deleted;
    },

    exists: async (key: string): Promise<boolean> => {
      const entry = cache.get(key);
      return entry ? entry.expires >= Date.now() : false;
    },

    ttl: async (key: string): Promise<number> => {
      const entry = cache.get(key);
      if (!entry) return -2;
      const remaining = entry.expires - Date.now();
      return remaining > 0 ? Math.floor(remaining / 1000) : -1;
    },

    health: async (): Promise<{ status: 'healthy' | 'unhealthy'; latency: number }> => {
      return { status: 'healthy', latency: 0 };
    }
  };
};

export interface CacheManager {
  get<T>(key: string): Promise<T | null>;
  set<T>(key: string, value: T, config: CacheConfig): Promise<void>;
  invalidate(key: string): Promise<void>;
  invalidateByTag(tag: string): Promise<void>;
  invalidateByPattern(pattern: string): Promise<void>;
  getStats(): Promise<CacheStats>;
  warmup(routes: readonly RouteDefinition[]): Promise<void>;
}

export const createAdvancedCacheManager = (
  provider: CacheProvider,
  config: {
    readonly keyPrefix: string;
    readonly defaultTtl: number;
    readonly maxKeyLength: number;
    readonly compressionThreshold: number;
  } = {
    keyPrefix: 'api:cache:',
    defaultTtl: 300,
    maxKeyLength: 250,
    compressionThreshold: 1024
  }
): CacheManager => {
  
  const stats = {
    hits: 0,
    misses: 0,
    sets: 0,
    invalidations: 0
  };

  const generateKey = (key: string): string => {
    const fullKey = `${config.keyPrefix}${key}`;
    if (fullKey.length > config.maxKeyLength) {
      // Hash long keys
      const crypto = require('crypto');
      return `${config.keyPrefix}hash:${crypto.createHash('sha256').update(key).digest('hex').substring(0, 32)}`;
    }
    return fullKey;
  };

  return {
    get: async <T>(key: string): Promise<T | null> => {
      try {
        const cacheKey = generateKey(key);
        const result = await provider.get<T>(cacheKey);
        
        if (result !== null) {
          stats.hits++;
        } else {
          stats.misses++;
        }
        
        return result;
      } catch (error) {
        console.error('Cache get error:', error);
        stats.misses++;
        return null;
      }
    },

    set: async <T>(key: string, value: T, cacheConfig: CacheConfig): Promise<void> => {
      try {
        const cacheKey = generateKey(key);
        const ttl = cacheConfig.ttl || config.defaultTtl;
        
        await provider.set(cacheKey, value, ttl);
        
        // Handle tags
        if (cacheConfig.tags) {
          for (const tag of cacheConfig.tags) {
            // Store tag -> key mapping for invalidation
            const tagKey = `${config.keyPrefix}tag:${tag}`;
            await provider.set(tagKey, [...(await provider.get<string[]>(tagKey) || []), cacheKey], ttl);
          }
        }
        
        stats.sets++;
      } catch (error) {
        console.error('Cache set error:', error);
      }
    },

    invalidate: async (key: string): Promise<void> => {
      try {
        const cacheKey = generateKey(key);
        await provider.del(cacheKey);
        stats.invalidations++;
      } catch (error) {
        console.error('Cache invalidate error:', error);
      }
    },

    invalidateByTag: async (tag: string): Promise<void> => {
      try {
        const deleted = await provider.delByTag(tag);
        stats.invalidations += deleted;
      } catch (error) {
        console.error('Cache invalidateByTag error:', error);
      }
    },

    invalidateByPattern: async (pattern: string): Promise<void> => {
      try {
        const fullPattern = `${config.keyPrefix}${pattern}`;
        const deleted = await provider.delByPattern(fullPattern);
        stats.invalidations += deleted;
      } catch (error) {
        console.error('Cache invalidateByPattern error:', error);
      }
    },

    getStats: async (): Promise<CacheStats> => {
      const health = await provider.health();
      const hitRate = stats.hits + stats.misses > 0 ? stats.hits / (stats.hits + stats.misses) : 0;
      
      return {
        ...stats,
        hitRate,
        provider: {
          status: health.status,
          latency: health.latency
        },
        generatedAt: new Date()
      };
    },

    warmup: async (routes: readonly RouteDefinition[]): Promise<void> => {
      console.log('üî• Starting cache warmup...');
      
      // Warmup common endpoints
      const warmupRoutes = routes.filter(route => 
        route.metadata.method === 'GET' && 
        (route.metadata as any).cache &&
        !route.metadata.path.includes(':') // No path parameters
      );

      for (const route of warmupRoutes) {
        try {
          // This would make actual HTTP requests to warm up the cache
          console.log(`Warming up: ${route.metadata.method} ${route.metadata.path}`);
          // await makeWarmupRequest(route);
        } catch (error) {
          console.warn(`Failed to warm up ${route.metadata.path}:`, error);
        }
      }
      
      console.log(`‚úÖ Cache warmup completed for ${warmupRoutes.length} routes`);
    }
  };
};

export interface CacheStats {
  readonly hits: number;
  readonly misses: number;
  readonly sets: number;
  readonly invalidations: number;
  readonly hitRate: number;
  readonly provider: {
    readonly status: 'healthy' | 'unhealthy';
    readonly latency: number;
  };
  readonly generatedAt: Date;
}
```

### **Smart Caching Middleware**

```typescript
// foundations/caching/cache-middleware.ts
export const createSmartCacheMiddleware = (
  cacheManager: CacheManager,
  config?: Partial<CacheConfig>
): MiddlewareDefinition => ({
  name: 'smart-cache',
  priority: 25,
  handler: async (context: UnifiedHttpContext): Promise<boolean> => {
    // Only cache GET requests
    if (context.request.method !== 'GET') {
      return true;
    }

    const cacheKey = generateCacheKey(context);
    const cacheConfig = config || { ttl: 300 };

    // Try to get from cache
    const cached = await cacheManager.get(cacheKey);
    if (cached) {
      context.response.header('X-Cache', 'HIT');
      context.response.header('X-Cache-Key', cacheKey);
      context.response.json(cached);
      return false; // Stop execution, response sent
    }

    // Cache miss - continue to route handler
    context.response.header('X-Cache', 'MISS');
    context.response.header('X-Cache-Key', cacheKey);

    // Override response to cache result
    const originalJson = context.response.json;
    context.response.json = function<T>(data: T) {
      // Cache the response asynchronously
      setImmediate(async () => {
        try {
          await cacheManager.set(cacheKey, data, cacheConfig);
        } catch (error) {
          console.error('Failed to cache response:', error);
        }
      });
      
      return originalJson.call(this, data);
    };

    return true; // Continue to route handler
  }
});

const generateCacheKey = (context: UnifiedHttpContext): string => {
  const url = new URL(context.request.url, 'http://localhost');
  const pathKey = url.pathname.replace(/\//g, ':');
  const queryKey = Array.from(url.searchParams.entries())
    .sort(([a], [b]) => a.localeCompare(b))
    .map(([key, value]) => `${key}=${value}`)
    .join('&');
  
  const user = getCurrentUser(context);
  const userKey = user ? `user:${user.sub}` : 'anonymous';
  
  return `route:${pathKey}:${userKey}:${queryKey}`;
};

// Cache invalidation middleware for POST/PUT/DELETE
export const createCacheInvalidationMiddleware = (
  cacheManager: CacheManager
): MiddlewareDefinition => ({
  name: 'cache-invalidation',
  priority: 30,
  handler: async (context: UnifiedHttpContext): Promise<boolean> => {
    // Only handle mutations
    if (!['POST', 'PUT', 'PATCH', 'DELETE'].includes(context.request.method)) {
      return true;
    }

    // Continue to route handler first
    const originalJson = context.response.json;
    context.response.json = function<T>(data: T) {
      // Invalidate related caches after successful response
      setImmediate(async () => {
        try {
          await invalidateRelatedCaches(context, cacheManager);
        } catch (error) {
          console.error('Failed to invalidate caches:', error);
        }
      });
      
      return originalJson.call(this, data);
    };

    return true;
  }
});

const invalidateRelatedCaches = async (
  context: UnifiedHttpContext,
  cacheManager: CacheManager
): Promise<void> => {
  const path = new URL(context.request.url, 'http://localhost').pathname;
  
  // Invalidate by resource pattern
  if (path.includes('/users')) {
    await cacheManager.invalidateByPattern('route:*users*');
    await cacheManager.invalidateByTag('users');
  }
  
  if (path.includes('/orders')) {
    await cacheManager.invalidateByPattern('route:*orders*');
    await cacheManager.invalidateByTag('orders');
  }

  // Invalidate user-specific caches
  const user = getCurrentUser(context);
  if (user) {
    await cacheManager.invalidateByPattern(`*user:${user.sub}*`);
  }
};
```

---

## 3. üè• **Operations & Health**

### **Health Check System**

```typescript
// foundations/health/health-checker.ts
export interface HealthCheck {
  readonly name: string;
  readonly critical: boolean;
  check(): Promise<HealthCheckResult>;
}

export interface HealthCheckResult {
  readonly status: 'healthy' | 'unhealthy' | 'degraded';
  readonly message?: string;
  readonly duration: number;
  readonly details?: Record<string, unknown>;
}

export interface OverallHealth {
  readonly status: 'healthy' | 'unhealthy' | 'degraded';
  readonly timestamp: Date;
  readonly checks: Record<string, HealthCheckResult>;
  readonly summary: {
    readonly total: number;
    readonly healthy: number;
    readonly unhealthy: number;
    readonly degraded: number;
  };
}

export const createDatabaseHealthCheck = (db: any): HealthCheck => ({
  name: 'database',
  critical: true,
  check: async (): Promise<HealthCheckResult> => {
    const start = Date.now();
    try {
      await db.query('SELECT 1'); // Simple connectivity check
      return {
        status: 'healthy',
        duration: Date.now() - start,
        details: { connected: true }
      };
    } catch (error) {
      return {
        status: 'unhealthy',
        message: error.message,
        duration: Date.now() - start,
        details: { connected: false, error: error.message }
      };
    }
  }
});

export const createCacheHealthCheck = (cacheProvider: CacheProvider): HealthCheck => ({
  name: 'cache',
  critical: false,
  check: async (): Promise<HealthCheckResult> => {
    const start = Date.now();
    try {
      const health = await cacheProvider.health();
      return {
        status: health.status === 'healthy' ? 'healthy' : 'degraded',
        duration: Date.now() - start,
        details: { latency: health.latency }
      };
    } catch (error) {
      return {
        status: 'degraded',
        message: error.message,
        duration: Date.now() - start,
        details: { error: error.message }
      };
    }
  }
});

export const createExternalServiceHealthCheck = (
  serviceName: string,
  healthUrl: string
): HealthCheck => ({
  name: serviceName,
  critical: false,
  check: async (): Promise<HealthCheckResult> => {
    const start = Date.now();
    try {
      // This would use fetch or axios in real implementation
      const response = await fetch(healthUrl, { 
        method: 'GET',
        timeout: 5000 
      });
      
      if (response.ok) {
        return {
          status: 'healthy',
          duration: Date.now() - start,
          details: { statusCode: response.status }
        };
      } else {
        return {
          status: 'degraded',
          message: `HTTP ${response.status}`,
          duration: Date.now() - start,
          details: { statusCode: response.status }
        };
      }
    } catch (error) {
      return {
        status: 'unhealthy',
        message: error.message,
        duration: Date.now() - start,
        details: { error: error.message }
      };
    }
  }
});

export const createSystemResourceHealthCheck = (): HealthCheck => ({
  name: 'system-resources',
  critical: true,
  check: async (): Promise<HealthCheckResult> => {
    const start = Date.now();
    try {
      const memUsage = process.memoryUsage();
      const cpuUsage = process.cpuUsage();
      const freeMemory = require('os').freemem();
      const totalMemory = require('os').totalmem();
      
      const memoryUsagePercent = (memUsage.rss / totalMemory) * 100;
      const freeMemoryPercent = (freeMemory / totalMemory) * 100;
      
      let status: 'healthy' | 'unhealthy' | 'degraded' = 'healthy';
      const issues: string[] = [];
      
      if (memoryUsagePercent > 90) {
        status = 'unhealthy';
        issues.push('Critical memory usage');
      } else if (memoryUsagePercent > 80) {
        status = 'degraded';
        issues.push('High memory usage');
      }
      
      if (freeMemoryPercent < 5) {
        status = 'unhealthy';
        issues.push('Critical low free memory');
      }

      return {
        status,
        message: issues.length > 0 ? issues.join(', ') : undefined,
        duration: Date.now() - start,
        details: {
          memory: {
            rss: memUsage.rss,
            heapUsed: memUsage.heapUsed,
            heapTotal: memUsage.heapTotal,
            external: memUsage.external,
            usagePercent: memoryUsagePercent
          },
          system: {
            freeMemory,
            totalMemory,
            freeMemoryPercent,
            loadAverage: require('os').loadavg()
          }
        }
      };
    } catch (error) {
      return {
        status: 'unhealthy',
        message: error.message,
        duration: Date.now() - start,
        details: { error: error.message }
      };
    }
  }
});

export interface HealthManager {
  registerCheck(check: HealthCheck): void;
  checkHealth(): Promise<OverallHealth>;
  checkReadiness(): Promise<OverallHealth>;
  startPeriodicChecks(intervalMs: number): void;
  stopPeriodicChecks(): void;
}

export const createHealthManager = (): HealthManager => {
  const checks = new Map<string, HealthCheck>();
  let periodicInterval: NodeJS.Timeout | null = null;

  return {
    registerCheck: (check: HealthCheck): void => {
      checks.set(check.name, check);
    },

    checkHealth: async (): Promise<OverallHealth> => {
      const timestamp = new Date();
      const results: Record<string, HealthCheckResult> = {};
      
      // Run all health checks in parallel
      const checkPromises = Array.from(checks.entries()).map(async ([name, check]) => {
        try {
          const result = await Promise.race([
            check.check(),
            new Promise<HealthCheckResult>((_, reject) => 
              setTimeout(() => reject(new Error('Health check timeout')), 10000)
            )
          ]);
          results[name] = result;
        } catch (error) {
          results[name] = {
            status: 'unhealthy',
            message: error.message,
            duration: 10000
          };
        }
      });

      await Promise.all(checkPromises);

      // Calculate overall status
      const checkResults = Object.values(results);
      const healthy = checkResults.filter(r => r.status === 'healthy').length;
      const unhealthy = checkResults.filter(r => r.status === 'unhealthy').length;
      const degraded = checkResults.filter(r => r.status === 'degraded').length;

      let overallStatus: 'healthy' | 'unhealthy' | 'degraded';
      
      // Any critical check failing = unhealthy
      const criticalChecks = Array.from(checks.values()).filter(c => c.critical);
      const failedCriticalChecks = criticalChecks.filter(check => 
        results[check.name]?.status === 'unhealthy'
      );
      
      if (failedCriticalChecks.length > 0) {
        overallStatus = 'unhealthy';
      } else if (unhealthy > 0 || degraded > 0) {
        overallStatus = 'degraded';
      } else {
        overallStatus = 'healthy';
      }

      return {
        status: overallStatus,
        timestamp,
        checks: results,
        summary: {
          total: checkResults.length,
          healthy,
          unhealthy,
          degraded
        }
      };
    },

    checkReadiness: async (): Promise<OverallHealth> => {
      // Readiness checks only critical services
      const criticalChecks = new Map(
        Array.from(checks.entries()).filter(([_, check]) => check.critical)
      );
      
      const timestamp = new Date();
      const results: Record<string, HealthCheckResult> = {};
      
      for (const [name, check] of criticalChecks) {
        try {
          results[name] = await check.check();
        } catch (error) {
          results[name] = {
            status: 'unhealthy',
            message: error.message,
            duration: 0
          };
        }
      }

      const checkResults = Object.values(results);
      const healthy = checkResults.filter(r => r.status === 'healthy').length;
      const unhealthy = checkResults.filter(r => r.status === 'unhealthy').length;
      const degraded = checkResults.filter(r => r.status === 'degraded').length;

      const overallStatus = unhealthy > 0 ? 'unhealthy' : 
                           degraded > 0 ? 'degraded' : 'healthy';

      return {
        status: overallStatus,
        timestamp,
        checks: results,
        summary: {
          total: checkResults.length,
          healthy,
          unhealthy,
          degraded
        }
      };
    },

    startPeriodicChecks: (intervalMs: number): void => {
      if (periodicInterval) return;

      periodicInterval = setInterval(async () => {
        try {
          const health = await createHealthManager().checkHealth();
          if (health.status === 'unhealthy') {
            console.error('üö® Health check failed:', health);
          }
        } catch (error) {
          console.error('Health check error:', error);
        }
      }, intervalMs);
    },

    stopPeriodicChecks: (): void => {
      if (periodicInterval) {
        clearInterval(periodicInterval);
        periodicInterval = null;
      }
    }
  };
};
```

### **Graceful Shutdown Manager**

```typescript
// foundations/operations/shutdown-manager.ts
export interface ShutdownManager {
  registerHandler(name: string, handler: () => Promise<void>): void;
  gracefulShutdown(signal: string): Promise<void>;
  forceShutdown(timeoutMs: number): void;
}

export const createGracefulShutdownManager = (logger: Logger): ShutdownManager => {
  const shutdownHandlers = new Map<string, () => Promise<void>>();
  let isShuttingDown = false;

  return {
    registerHandler: (name: string, handler: () => Promise<void>): void => {
      shutdownHandlers.set(name, handler);
    },

    gracefulShutdown: async (signal: string): Promise<void> => {
      if (isShuttingDown) {
        logger.warn('Shutdown already in progress');
        return;
      }

      isShuttingDown = true;
      logger.info(`üö™ Graceful shutdown initiated by ${signal}`);

      const shutdownTimeout = setTimeout(() => {
        logger.error('‚è∞ Graceful shutdown timeout - forcing exit');
        process.exit(1);
      }, 30000); // 30 second timeout

      try {
        // Execute shutdown handlers in reverse order (LIFO)
        const handlers = Array.from(shutdownHandlers.entries()).reverse();
        
        for (const [name, handler] of handlers) {
          try {
            logger.info(`üîÑ Shutting down: ${name}`);
            await handler();
            logger.info(`‚úÖ Shutdown complete: ${name}`);
          } catch (error) {
            logger.error(`‚ùå Shutdown error for ${name}:`, error);
          }
        }

        clearTimeout(shutdownTimeout);
        logger.info('‚úÖ Graceful shutdown completed');
        process.exit(0);
      } catch (error) {
        clearTimeout(shutdownTimeout);
        logger.error('‚ùå Graceful shutdown failed:', error);
        process.exit(1);
      }
    },

    forceShutdown: (timeoutMs: number): void => {
      setTimeout(() => {
        logger.error('üíÄ Force shutdown - immediate exit');
        process.exit(1);
      }, timeoutMs);
    }
  };
};

// Circuit breaker for external services
export interface CircuitBreakerConfig {
  readonly failureThreshold: number;
  readonly resetTimeoutMs: number;
  readonly monitoringPeriodMs: number;
  readonly volumeThreshold: number;
}

export interface CircuitBreaker {
  execute<T>(operation: () => Promise<T>): Promise<T>;
  getState(): 'CLOSED' | 'OPEN' | 'HALF_OPEN';
  getMetrics(): CircuitBreakerMetrics;
}

export const createCircuitBreaker = (
  name: string,
  config: CircuitBreakerConfig
): CircuitBreaker => {
  let state: 'CLOSED' | 'OPEN' | 'HALF_OPEN' = 'CLOSED';
  let failureCount = 0;
  let successCount = 0;
  let lastFailureTime = 0;
  const requestCounts: Array<{ timestamp: number; success: boolean }> = [];

  const shouldAttemptReset = (): boolean => {
    return state === 'OPEN' && 
           (Date.now() - lastFailureTime) >= config.resetTimeoutMs;
  };

  const updateCounts = (success: boolean): void => {
    const now = Date.now();
    requestCounts.push({ timestamp: now, success });
    
    // Remove old entries outside monitoring period
    const cutoff = now - config.monitoringPeriodMs;
    while (requestCounts.length > 0 && requestCounts[0].timestamp < cutoff) {
      requestCounts.shift();
    }
  };

  const calculateFailureRate = (): number => {
    if (requestCounts.length < config.volumeThreshold) {
      return 0;
    }
    
    const failures = requestCounts.filter(r => !r.success).length;
    return failures / requestCounts.length;
  };

  return {
    execute: async <T>(operation: () => Promise<T>): Promise<T> => {
      if (state === 'OPEN') {
        if (shouldAttemptReset()) {
          state = 'HALF_OPEN';
          console.log(`Circuit breaker ${name}: transitioning to HALF_OPEN`);
        } else {
          throw new Error(`Circuit breaker ${name} is OPEN`);
        }
      }

      try {
        const result = await operation();
        
        // Success
        updateCounts(true);
        successCount++;
        
        if (state === 'HALF_OPEN') {
          state = 'CLOSED';
          failureCount = 0;
          console.log(`Circuit breaker ${name}: transitioning to CLOSED`);
        }
        
        return result;
      } catch (error) {
        // Failure
        updateCounts(false);
        failureCount++;
        lastFailureTime = Date.now();
        
        const failureRate = calculateFailureRate();
        
        if (state === 'HALF_OPEN' || 
            (state === 'CLOSED' && failureRate >= config.failureThreshold)) {
          state = 'OPEN';
          console.log(`Circuit breaker ${name}: transitioning to OPEN (failure rate: ${failureRate})`);
        }
        
        throw error;
      }
    },

    getState: (): 'CLOSED' | 'OPEN' | 'HALF_OPEN' => state,

    getMetrics: (): CircuitBreakerMetrics => ({
      state,
      failureCount,
      successCount,
      failureRate: calculateFailureRate(),
      lastFailureTime: lastFailureTime > 0 ? new Date(lastFailureTime) : null,
      requestCount: requestCounts.length
    })
  };
};

export interface CircuitBreakerMetrics {
  readonly state: 'CLOSED' | 'OPEN' | 'HALF_OPEN';
  readonly failureCount: number;
  readonly successCount: number;
  readonly failureRate: number;
  readonly lastFailureTime: Date | null;
  readonly requestCount: number;
}
```

---

## üöÄ **Putting It All Together - Part 3**

### **Production-Ready Setup**

```typescript
// app-production.ts - Complete production setup
import { Hono } from 'hono';
import Redis from 'ioredis';

const setupProductionApplication = async () => {
  // 1. Initialize infrastructure
  const redis = new Redis(process.env.REDIS_URL || 'redis://localhost:6379');
  const logger = createLogger({ 
    level: process.env.LOG_LEVEL || 'info',
    format: 'json' // Structured logging for production
  });

  // 2. Create advanced services
  const cacheProvider = createRedisCacheProvider(redis);
  const cacheManager = createAdvancedCacheManager(cacheProvider, {
    keyPrefix: 'api:v1:',
    defaultTtl: 300,
    maxKeyLength: 250,
    compressionThreshold: 1024
  });

  const metricsCollector = createAdvancedMetricsCollector({
    slowRequestThreshold: 1000,
    highErrorRateThreshold: 0.05,
    memoryLeakThreshold: 100 * 1024 * 1024,
    cpuThreshold: 80,
    eventLoopThreshold: 100,
    alertingEnabled: true,
    retentionDays: 30
  });

  // 3. Setup health checks
  const healthManager = createHealthManager();
  healthManager.registerCheck(createDatabaseHealthCheck(/* database instance */));
  healthManager.registerCheck(createCacheHealthCheck(cacheProvider));
  healthManager.registerCheck(createSystemResourceHealthCheck());
  healthManager.registerCheck(createExternalServiceHealthCheck('auth-service', 'https://auth.service.com/health'));

  // 4. Setup graceful shutdown
  const shutdownManager = createGracefulShutdownManager(logger);
  
  shutdownManager.registerHandler('metrics', async () => {
    metricsCollector.stopMonitoring();
  });
  
  shutdownManager.registerHandler('health-checks', async () => {
    healthManager.stopPeriodicChecks();
  });
  
  shutdownManager.registerHandler('cache', async () => {
    await redis.quit();
  });

  // Register shutdown signals
  process.on('SIGTERM', () => shutdownManager.gracefulShutdown('SIGTERM'));
  process.on('SIGINT', () => shutdownManager.gracefulShutdown('SIGINT'));

  // 5. Create circuit breakers for external services
  const authServiceBreaker = createCircuitBreaker('auth-service', {
    failureThreshold: 0.5,
    resetTimeoutMs: 60000,
    monitoringPeriodMs: 60000,
    volumeThreshold: 10
  });

  // 6. Setup middleware from all parts
  const registry = createRouteRegistry();
  const middlewareRegistry = createMiddlewareRegistry();

  // Part 1 middleware
  middlewareRegistry.register(createErrorHandlingMiddleware());
  middlewareRegistry.register(createRequestLoggingMiddleware());
  middlewareRegistry.register(createCorsMiddleware({
    origin: process.env.ALLOWED_ORIGINS?.split(',') || ['*'],
    methods: ['GET', 'POST', 'PUT', 'DELETE'],
    allowedHeaders: ['Content-Type', 'Authorization', 'X-API-Version', 'X-Correlation-ID']
  }));

  // Part 2 middleware  
  const authService = createAuthService({
    jwtSecret: process.env.JWT_SECRET!,
    issuer: process.env.JWT_ISSUER!
  });
  
  middlewareRegistry.register(createAuthMiddleware(authService, { required: true }));
  middlewareRegistry.register(createRateLimitMiddleware({
    max: parseInt(process.env.RATE_LIMIT_MAX || '100'),
    window: process.env.RATE_LIMIT_WINDOW || '1h'
  }, createRedisCacheProvider(redis)));
  middlewareRegistry.register(createSecurityHeadersMiddleware());

  // Part 3 middleware
  middlewareRegistry.register(createRequestCorrelationMiddleware());
  middlewareRegistry.register(createSmartCacheMiddleware(cacheManager));
  middlewareRegistry.register(createCacheInvalidationMiddleware(cacheManager));

  // 7. Create production routes with all features
  const userDeps: UserDependencies = {
    logger,
    userService: createUserService(),
    emailService: createEmailService(),
    cacheService: cacheProvider
  };

  const createRoute = createRouteWithDeps(userDeps);

  const getUsersRoute = createRoute(
    {
      method: 'GET',
      path: '/v2/users',
      tags: ['users'],
      summary: 'List users (production)',
      cache: { ttl: 300, tags: ['users'] }
    },
    {
      query: z.object({
        page: z.coerce.number().min(1).default(1),
        limit: z.coerce.number().min(1).max(100).default(20),
        search: z.string().optional()
      })
    },
    async (validated, context, deps) => {
      // Add performance tracking
      const performanceMiddleware = createPerformanceTrackingMiddleware(
        metricsCollector, 
        getUsersRoute
      );
      
      const users = await deps.userService.getUsers(validated.query);
      
      context.response.json({
        data: users,
        meta: {
          timestamp: new Date().toISOString(),
          version: 'v2',
          cached: context.response.headers?.['x-cache'] === 'HIT'
        }
      });
    }
  );

  // Apply all middleware
  const enhancedRoute = withMiddleware(
    getUsersRoute,
    [
      'error-handling',
      'request-correlation', 
      'request-logging',
      'cors',
      'security-headers',
      'auth',
      'rate-limit',
      'smart-cache',
      'cache-invalidation'
    ],
    middlewareRegistry
  );

  // 8. Setup route manager
  const routeManager = createRouteManager(
    {
      discovery: { patterns: ['./routes/**/*.route.ts'] },
      middleware: { global: ['error-handling', 'request-correlation', 'request-logging'] }
    },
    {
      registry,
      discoveryService: createRouteDiscoveryService(createFileSystemService()),
      middlewareRegistry
    }
  );

  routeManager.register(enhancedRoute);

  // 9. Setup Hono app
  const app = new Hono();

  // Add global error handler
  app.onError((err, c) => {
    logger.error('Unhandled error:', err);
    return c.json({ error: 'Internal server error' }, 500);
  });

  await routeManager.setupFramework(app, 'hono');

  // 10. Production endpoints
  
  // Health endpoints
  app.get('/health', async (c) => {
    const health = await healthManager.checkHealth();
    const status = health.status === 'healthy' ? 200 : 
                   health.status === 'degraded' ? 200 : 503;
    return c.json(health, status);
  });

  app.get('/health/ready', async (c) => {
    const readiness = await healthManager.checkReadiness();
    const status = readiness.status === 'healthy' ? 200 : 503;
    return c.json(readiness, status);
  });

  // Metrics endpoints
  app.get('/metrics', async (c) => {
    const routeMetrics = await metricsCollector.getRouteMetrics();
    const systemMetrics = await metricsCollector.getSystemMetrics();
    const cacheStats = await cacheManager.getStats();
    const alerts = await metricsCollector.getActiveAlerts();

    return c.json({
      timestamp: new Date().toISOString(),
      routes: routeMetrics,
      system: systemMetrics,
      cache: cacheStats,
      alerts,
      circuitBreakers: {
        authService: authServiceBreaker.getMetrics()
      }
    });
  });

  app.get('/metrics/performance', async (c) => {
    const report = await metricsCollector.generatePerformanceReport();
    return c.json(report);
  });

  // Cache management endpoints
  app.delete('/cache/:pattern', async (c) => {
    const pattern = c.req.param('pattern');
    await cacheManager.invalidateByPattern(pattern);
    return c.json({ message: `Cache invalidated for pattern: ${pattern}` });
  });

  app.delete('/cache/tag/:tag', async (c) => {
    const tag = c.req.param('tag');
    await cacheManager.invalidateByTag(tag);
    return c.json({ message: `Cache invalidated for tag: ${tag}` });
  });

  app.get('/cache/stats', async (c) => {
    const stats = await cacheManager.getStats();
    return c.json(stats);
  });

  // 11. Start monitoring
  metricsCollector.startMonitoring();
  healthManager.startPeriodicChecks(30000); // Every 30 seconds

  // 12. Cache warmup
  await cacheManager.warmup(routeManager.getRoutes());

  logger.info('üöÄ Production application initialized', {
    routes: routeManager.getRoutes().length,
    middleware: middlewareRegistry.getAll().length,
    features: [
      'performance-monitoring',
      'advanced-caching',
      'health-checks',
      'graceful-shutdown',
      'circuit-breakers',
      'structured-logging',
      'metrics-collection',
      'security-headers',
      'rate-limiting',
      'request-correlation'
    ]
  });

  return { app, shutdown: shutdownManager };
};

// Production deployment
if (require.main === module) {
  setupProductionApplication()
    .then(({ app, shutdown }) => {
      const port = parseInt(process.env.PORT || '3000');
      
      // Start server
      if (typeof Bun !== 'undefined') {
        Bun.serve({ port, fetch: app.fetch });
        console.log(`üî• Production server running on port ${port} (Bun)`);
      } else {
        const { serve } = require('@hono/node-server');
        serve({ fetch: app.fetch, port });
        console.log(`üü¢ Production server running on port ${port} (Node.js)`);
      }

      // Production readiness
      console.log('‚úÖ Production endpoints:');
      console.log(`üìä Metrics: http://localhost:${port}/metrics`);
      console.log(`üè• Health: http://localhost:${port}/health`);
      console.log(`üéØ Readiness: http://localhost:${port}/health/ready`);
      console.log(`üíæ Cache Stats: http://localhost:${port}/cache/stats`);
    })
    .catch((error) => {
      console.error('‚ùå Failed to start production server:', error);
      process.exit(1);
    });
}
```

---

## üìù Part 3 Summary

### What You've Built

**‚úÖ 1. Performance Monitoring**
- Advanced metrics collection with percentiles (P95, P99)
- Real-time performance alerts (slow routes, high error rates, memory leaks)
- System monitoring (CPU, memory, event loop, GC)
- Request correlation and distributed tracing
- Performance reports with recommendations

**‚úÖ 2. Caching System**
- Redis-backed intelligent caching with TTL
- Smart cache invalidation by tags and patterns
- Stale-while-revalidate strategies
- Cache warmup for common endpoints
- Cache analytics and hit rate monitoring

**‚úÖ 3. Operations & Health**
- Comprehensive health checks (database, cache, external services)
- Graceful shutdown with proper cleanup
- Circuit breakers for external service reliability
- Production-ready error handling
- Readiness and liveness probes for Kubernetes

### üöÄ Production Features Added

**Performance Monitoring:**
- Request tracking with response time percentiles
- Memory usage and event loop monitoring
- Automatic alert generation for performance issues
- Correlation IDs for request tracing

**Advanced Caching:**
- Redis integration with fallback to in-memory
- Intelligent cache key generation
- Tag-based invalidation strategies
- Cache warming and preloading

**Operations Excellence:**
- Health check endpoints for load balancers
- Graceful shutdown handling
- Circuit breaker pattern for resilience
- Structured logging for observability

### üìä Monitoring & Observability

```bash
# Production endpoints
GET  /health              # Overall health status
GET  /health/ready        # Readiness probe (K8s)
GET  /metrics             # Complete metrics dashboard
GET  /metrics/performance # Performance analysis
GET  /cache/stats         # Cache performance
```

### üè• Operational Excellence

- **Zero-downtime deployments** with graceful shutdown
- **Circuit breakers** prevent cascade failures  
- **Health checks** for orchestration platforms
- **Performance alerts** for proactive monitoring
- **Cache optimization** for improved response times

### Learning Outcome

‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∏‡∏ì‡∏°‡∏µ **enterprise-grade production API** ‡∏ó‡∏µ‡πà‡∏°‡∏µ:
- ‚úÖ **Complete Monitoring** - Performance, health, alerts
- ‚úÖ **Advanced Caching** - Redis, intelligent invalidation
- ‚úÖ **Production Operations** - Health checks, graceful shutdown
- ‚úÖ **Resilience Patterns** - Circuit breakers, retry logic
- ‚úÖ **Observability** - Metrics, tracing, structured logging
- ‚úÖ **Kubernetes Ready** - Health/readiness probes
- ‚úÖ **Zero-downtime** - Graceful shutdown and cache warmup

**Ready for enterprise production deployment!** üéØ

### Complete Journey Summary

**Part 1 (Foundation)** ‚Üí **Part 2 (Security)** ‚Üí **Part 3 (Operations)**

‡∏à‡∏≤‡∏Å simple route management ‡πÑ‡∏õ‡∏™‡∏π‡πà **enterprise-grade API platform** ‡∏ó‡∏µ‡πà‡∏û‡∏£‡πâ‡∏≠‡∏° scale ‡πÅ‡∏•‡∏∞ operate ‡πÉ‡∏ô production environment ‡πÅ‡∏ö‡∏ö‡∏°‡∏∑‡∏≠‡∏≠‡∏≤‡∏ä‡∏µ‡∏û! üåü